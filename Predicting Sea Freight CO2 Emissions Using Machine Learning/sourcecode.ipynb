{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c684c851-5cf7-49ba-965d-986d546ea9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vighn\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Polynomial SVM: {'C': 10, 'degree': 3, 'epsilon': 0.01}\n",
      "Linear SVM Results:\n",
      "Mean Squared Error: 364785818602.37164\n",
      "Mean Absolute Error: 428945.22011687467\n",
      "R2 Score: -0.3776129249610687\n",
      "Training Time: 0.004000425338745117 seconds\n",
      "Memory Usage: 225.22265625 MB\n",
      "\n",
      "Additional Linear SVM Results:\n",
      "Root Mean Squared Error (RMSE): 603975.014882546\n",
      "Explained Variance Score (EVS): 0.010282180316335099\n",
      "Mean Bias Deviation (MBD): 320488.55022175325\n",
      "Median Absolute Error (MedAE): 194720.56726778147\n",
      "\n",
      "Polynomial SVM Results:\n",
      "Mean Squared Error: 367514867625.2616\n",
      "Mean Absolute Error: 430671.04800859885\n",
      "R2 Score: -0.38791917321707237\n",
      "Training Time: 0.5316920280456543 seconds\n",
      "Memory Usage: 225.23046875 MB\n",
      "\n",
      "Additional Polynomial SVM Results:\n",
      "Root Mean Squared Error (RMSE): 606230.0451357237\n",
      "Explained Variance Score (EVS): 0.004047803492014612\n",
      "Mean Bias Deviation (MBD): 322166.2992862817\n",
      "Median Absolute Error (MedAE): 196649.6518449306\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,explained_variance_score, median_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Load the dataset (replace with your path)\n",
    "df = pd.read_csv('E:/assignment/et/report/work500.csv')\n",
    "\n",
    "# Data cleaning (drop irrelevant columns)\n",
    "irrelevant_columns = ['TimePosition', 'SourcePosition', 'Latitude', 'Longitude', 'Course', 'NavStatus',\n",
    "                      'TimeVoyage', 'SourceVoyage', 'IMO', 'Name', 'Callsign', 'Flag', 'DimA', 'DimB',\n",
    "                      'DimC', 'DimD', 'Destination', 'TimeETA']\n",
    "\n",
    "columns_to_drop = [col for col in irrelevant_columns if col in df.columns]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove outliers (for example, speeds or draughts above 99th percentile)\n",
    "df = df[(df['Speed'] <= df['Speed'].quantile(0.99)) & \n",
    "        (df['Draught'] <= df['Draught'].quantile(0.99))]\n",
    "\n",
    "# Create a synthetic target column 'CO2_Emissions' for demonstration (highly non-linear relationship)\n",
    "df['CO2_Emissions'] = 0.1 * (df['Speed'] ** 2) + 0.3 * np.sin(df['Draught']) + 0.2 * (df['Length'] ** 3) + 0.05 * np.cos(df['Width']) + np.random.randn(len(df))\n",
    "\n",
    "# Create interaction terms between features\n",
    "df['Speed_Draught'] = df['Speed'] * df['Draught']\n",
    "df['Length_Width'] = df['Length'] * df['Width']\n",
    "\n",
    "# Introduce non-linear terms (squared and cubic terms)\n",
    "df['Speed_squared'] = df['Speed'] ** 2\n",
    "df['Draught_squared'] = df['Draught'] ** 2\n",
    "df['Length_cubed'] = df['Length'] ** 3\n",
    "\n",
    "# Trigonometric transformations (to create non-linearity)\n",
    "df['sin_Length'] = np.sin(df['Length'])\n",
    "df['cos_Width'] = np.cos(df['Width'])\n",
    "\n",
    "# Introduce exponential terms\n",
    "df['exp_Speed'] = np.exp(df['Speed'] / 100)  # Keep the value reasonable by dividing\n",
    "\n",
    "# Label encoding for categorical feature 'VesselType'\n",
    "le = LabelEncoder()\n",
    "df['VesselType'] = le.fit_transform(df['VesselType'])  # Encode 'VesselType'\n",
    "\n",
    "# Apply KMeans clustering to add a new feature representing cluster memberships\n",
    "X = df.drop(columns='CO2_Emissions')  # Exclude the target variable\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X)  # Adding cluster labels as a feature\n",
    "\n",
    "# Apply PCA to reduce dimensionality but retain the complexity\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Adding PCA components to the original dataset\n",
    "df['PCA1'] = X_pca[:, 0]\n",
    "df['PCA2'] = X_pca[:, 1]\n",
    "\n",
    "# Example of domain-based feature engineering\n",
    "df['Vessel_Volume'] = df['Length'] * df['Width'] * df['Draught']\n",
    "\n",
    "# Generate polynomial features (quadratic in this example)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop(columns='CO2_Emissions')\n",
    "y = df['CO2_Emissions']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize Linear SVM model\n",
    "linear_svm = SVR(kernel='linear')\n",
    "\n",
    "# Initialize Polynomial SVM model with hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],           # Regularization strength\n",
    "    'epsilon': [0.01, 0.1, 0.5],  # Margin of error for SVR\n",
    "    'degree': [2, 3, 4]           # Polynomial degree\n",
    "}\n",
    "\n",
    "poly_svm = SVR(kernel='poly')\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters for Polynomial SVM\n",
    "grid_search = GridSearchCV(estimator=poly_svm, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# Function to calculate Root Mean Squared Error (RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Function to calculate Mean Bias Deviation (MBD)\n",
    "def mean_bias_deviation(y_true, y_pred):\n",
    "    return np.mean(y_true - y_pred)\n",
    "    \n",
    "# Track memory usage\n",
    "def memory_usage():\n",
    "    process = psutil.Process()\n",
    "    x =round(process.memory_info().rss / (1024 ** 2) ,2) # Convert to MB\n",
    "    return x\n",
    "    \n",
    "\n",
    "# Train Linear SVM\n",
    "start_time_linear = time.time()\n",
    "linear_svm.fit(X_train_scaled, y_train)\n",
    "linear_time = time.time() - start_time_linear\n",
    "linear_memory = memory_usage()\n",
    "\n",
    "# Train Polynomial SVM with GridSearchCV\n",
    "start_time_poly = time.time()\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "poly_time = time.time() - start_time_poly\n",
    "poly_memory = memory_usage()\n",
    "\n",
    "# Output best parameters for Polynomial SVM\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters for Polynomial SVM: {best_params}\")\n",
    "\n",
    "# Train the best Polynomial SVM model\n",
    "best_poly_svm = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data using both models\n",
    "y_pred_linear = linear_svm.predict(X_test_scaled)\n",
    "y_pred_poly = best_poly_svm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the models (accuracy)\n",
    "linear_mse = mean_squared_error(y_test, y_pred_linear)\n",
    "linear_mae = mean_absolute_error(y_test, y_pred_linear)\n",
    "linear_r2 = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "poly_mse = mean_squared_error(y_test, y_pred_poly)\n",
    "poly_mae = mean_absolute_error(y_test, y_pred_poly)\n",
    "poly_r2 = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "\n",
    "# Evaluate the models using additional metrics\n",
    "linear_rmse = rmse(y_test, y_pred_linear)\n",
    "linear_evs = explained_variance_score(y_test, y_pred_linear)\n",
    "linear_mbd = mean_bias_deviation(y_test, y_pred_linear)\n",
    "linear_medae = median_absolute_error(y_test, y_pred_linear)\n",
    "\n",
    "poly_rmse = rmse(y_test, y_pred_poly)\n",
    "poly_evs = explained_variance_score(y_test, y_pred_poly)\n",
    "poly_mbd = mean_bias_deviation(y_test, y_pred_poly)\n",
    "poly_medae = median_absolute_error(y_test, y_pred_poly)\n",
    "\n",
    "# Output the additional metrics for Linear SVM\n",
    "\n",
    "\n",
    "# Output the additional metrics for Polynomial SVM\n",
    "\n",
    "\n",
    "# Output the results for Linear SVM\n",
    "print(\"Linear SVM Results:\")\n",
    "print(f\"Mean Squared Error: {linear_mse}\")\n",
    "print(f\"Mean Absolute Error: {linear_mae}\")\n",
    "print(f\"R2 Score: {linear_r2}\")\n",
    "print(f\"Training Time: {linear_time} seconds\")\n",
    "print(f\"Memory Usage: {linear_memory} MB\")\n",
    "print(\"\\nAdditional Linear SVM Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {linear_rmse}\")\n",
    "print(f\"Explained Variance Score (EVS): {linear_evs}\")\n",
    "print(f\"Mean Bias Deviation (MBD): {linear_mbd}\")\n",
    "print(f\"Median Absolute Error (MedAE): {linear_medae}\")\n",
    "\n",
    "# Output the results for Polynomial SVM\n",
    "print(\"\\nPolynomial SVM Results:\")\n",
    "print(f\"Mean Squared Error: {poly_mse}\")\n",
    "print(f\"Mean Absolute Error: {poly_mae}\")\n",
    "print(f\"R2 Score: {poly_r2}\")\n",
    "print(f\"Training Time: {poly_time} seconds\")\n",
    "print(f\"Memory Usage: {poly_memory} MB\")\n",
    "print(\"\\nAdditional Polynomial SVM Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {poly_rmse}\")\n",
    "print(f\"Explained Variance Score (EVS): {poly_evs}\")\n",
    "print(f\"Mean Bias Deviation (MBD): {poly_mbd}\")\n",
    "print(f\"Median Absolute Error (MedAE): {poly_medae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7839225b-2419-42ac-97d5-94865a96d581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
